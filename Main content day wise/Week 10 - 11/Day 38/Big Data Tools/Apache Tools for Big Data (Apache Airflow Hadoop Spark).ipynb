{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bc666-34a1-47b6-8018-1ad79dafae95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #add8e6; padding: 10px; height: 70px; border-radius: 15px;\">\n",
    "    <div style=\"font-family: 'Georgia', serif; font-size: 20px; padding: 10px; text-align: right; position: absolute; right: 20px;\">\n",
    "        Mohammad Idrees Bhat <br>\n",
    "        <span style=\"font-family: 'Arial', sans-serif;font-size: 12px; color: #0a0a0a;\">Tech Skills Trainer | AI/ML Consultant</span> <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444d2e-97e9-49a8-bf3d-0119a2dfebb5",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ad3d8-0bce-4e29-86da-5ea91b5a69df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; padding: 10px; text-align: center; color: white; font-size: 32px; font-family: 'Arial', sans-serif;\">\n",
    "    Apache Tools for Big Data <br>\n",
    "    <h3 style=\"text-align: center; color: white; font-size: 15px; font-family: 'Arial', sans-serif;\">Apache Airflow for ETL pipelines</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e8ec7-547b-41f4-b6f6-6e6e719c198c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; color: black; padding: 10px;\">\n",
    "    <h4><b>AGENDA</b> <p><p>\n",
    "1.  Use Apache Airflow for ETL Pipelines <p>\n",
    "2.  Connect Airflow Scheduler to Postgres database\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c30b-e766-4658-8d70-1b0af10ae2f4",
   "metadata": {},
   "source": [
    "<!-- Link the Montserrat font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<!-- Main div with centered content and a flexible box size, no scroll bar -->\n",
    "<div style=\"background-color: #baf733; min-height: 100px; width: 100%; display: flex; justify-content: center; align-items: center; position: relative; padding: 20px; box-sizing: border-box; font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 20px; border-radius: 15px;\">\n",
    "    <div style=\"position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 14px; color: rgba(0, 0, 0, 0.05); border-radius: 10px;\">Mohammad Idrees Bhat</div>\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the below text with question -->\n",
    "    In all that you do, be kind!\n",
    "    <!-- Fill the above text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec8637",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>1. Using Apache Airflow\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c762cd6-ee35-4e4e-aa54-600db6a9c23d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4> Install the dependencies\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aafc340",
   "metadata": {},
   "source": [
    "Extraction\n",
    "\n",
    "we will scrape amazon books, \n",
    "\n",
    "clean and transformed data\n",
    "\n",
    "is loaded\n",
    "\n",
    "stored in data warehouse\n",
    "\n",
    "- Airflow will help us schedule tasks\n",
    "    (docker with airflow)\n",
    "    - scheduler\n",
    "    - webserver for ui\n",
    "    - \n",
    "\n",
    "\n",
    "- Python as primary language, and SQL for querries\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6d7ab9b9",
   "metadata": {},
   "source": [
    "Step 1 is to create and activate a new virtual environment\n",
    "\n",
    "- Download python 3.8 at some place, most likely the path will look like this: `C:\\Users\\devid\\AppData\\Local\\Programs\\Python\\Python38`\n",
    "- Use this command to create the environment:\n",
    "`C:\\Users\\<username>\\AppData\\Local\\Programs\\Python\\Python38\\python.exe -m venv <environment_name>`\n",
    "- In the terminal, (a cmd terminal in VS code, not powershell) use this command:\n",
    "`<environment_name>\\Scripts\\activate`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b73c63bf",
   "metadata": {},
   "source": [
    "Step 2: Install docker and airflow\n",
    "\n",
    "**1.** Go to this page:\n",
    "https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html\n",
    "- Ensure that docker compose is installed:\n",
    "`docker compose version`\n",
    "- If it is not installed, use this: \n",
    "[Docker Windows](https://docs.docker.com/desktop/setup/install/windows-install/) or [Docker Mac](https://docs.docker.com/desktop/setup/install/mac-install/)\n",
    "**2.** Copy the **Fetching docker-compose.yaml** command and paste in the activated terminal in Linux/Mac:\n",
    "\n",
    "    `curl -LfO 'https://airflow.apache.org/docs/apache-airflow/2.10.3/docker-compose.yaml'`\n",
    "\n",
    "- But use double quotes on windows:\n",
    "\n",
    "    `curl -LfO \"https://airflow.apache.org/docs/apache-airflow/2.10.3/docker-compose.yaml\"`\n",
    "\n",
    "**3.** Then use this on Linux/Mac:\n",
    "    ```bash\n",
    "    mkdir -p ./dags ./logs ./plugins ./config\n",
    "    echo -e \"AIRFLOW_UID=$(id -u)\" > .env\n",
    "    ```\n",
    "\n",
    "- But use this on windows:\n",
    "    ```bash\n",
    "    mkdir dags logs plugins config \n",
    "    echo AIRFLOW_UID=50000 > .env\n",
    "    ```\n",
    "These commands create the folders dags, logs, plugins, config and another `.env` file\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a699c7b",
   "metadata": {},
   "source": [
    "The next step will require docker to be present on your system, in your environment, and running to execute the command.\n",
    "\n",
    "**4.** Initialilze database, use this command:\n",
    "    `docker compose up airflow-init`\n",
    "\n",
    "**5.** Start all services using:\n",
    "    `docker compose up`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96bb8264",
   "metadata": {},
   "source": [
    "Then we can visit `localhost:8080` from our browser to see the airflow interface"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e85ad0",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "698b9e38",
   "metadata": {},
   "source": [
    "- Add new port to the `docker-compose.yaml` file within `services:`\n",
    "\n",
    "```yml\n",
    "    ports:\n",
    "      -  \"5432:5432\"\n",
    "```\n",
    "\n",
    "- Next add one more port:\n",
    "\n",
    "```yml\n",
    "  pgadmin:\n",
    "      container_name: pgadmin4_container2   \n",
    "      image: dpage/pgadmin4  \n",
    "      restart: always \n",
    "      environment:\n",
    "        PGADMIN_DEFAULT_EMAIL: admin@admin.com\n",
    "        PGADMIN_DEFAULT_PASSWORD: root\n",
    "      ports:\n",
    "        -  \"5050:80\"\n",
    "```\n",
    "- Then open a new command prompt and close the docker container using:\n",
    "`docker compose down`\n",
    "\n",
    "- Then start the docker container again using:\n",
    "`docker compose up`\n",
    "\n",
    "- Go to localhost:5050 and login to pgadmin, with the username password setup earlier. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b551d85",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>2. Connect to Postgres Database\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ad244b",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321f7033",
   "metadata": {},
   "source": [
    "Create a **pgadmin** connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac4074e0",
   "metadata": {},
   "source": [
    "Go to pgadmin **create a new server**\n",
    "Name it as `ps_db`\n",
    "Go to connections and add the host name\n",
    "\n",
    "- We will get the host name from the docker container:\n",
    "    - add a new terminal and run `docker container ls`\n",
    "    - find the postgres id and copy it \n",
    "    - then run command `docker inspect <id>` in our case `docker inspect 606a0b6731dc`\n",
    "    - find the ip address in the output which will look like `172.18.0.2`, maybe a different value for you\n",
    "- Paste the ip address in the hostname \n",
    "- Username is airflow and pw is airflow\n",
    "- And you are connected\n",
    "\n",
    "- Create a new database in pgadmin, named `amazon_books`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73e8fc67",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "- Go to airflow\n",
    "- Go to Admin\n",
    "- Create a new connection\n",
    "- Name it as `books_connection`, db is `amazon_books` and port is `5432` (specifics may differ for others)\n",
    "- Login is airflow and pw is airflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5655a5ce",
   "metadata": {},
   "source": [
    "---\n",
    "Create a DAG \n",
    "\n",
    "We will have:\n",
    "    - Tasks \n",
    "        - Fetch data (Extract)\n",
    "        - clean (Transform)\n",
    "        - store in a table in postgres (Load)\n",
    "    - Operators\n",
    "    - Hooks - allow connection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee7dd0e8",
   "metadata": {},
   "source": [
    "if you create a new dag, you will need to restart the container\n",
    "\n",
    "this might also change the IP addresses of the dependencies, so watch out for that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26d311ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Title  \\\n",
      "0                          Data Engineering on Azure   \n",
      "1                       Data Engineering with Python   \n",
      "2        Data Engineering with Google Cloud Platform   \n",
      "3  Data Engineering with Apache Spark, Delta Lake...   \n",
      "4                   Fundamentals of Data Engineering   \n",
      "5          97 Things Every Data Engineer Should Know   \n",
      "6                                      The Rails Way   \n",
      "7                           The Pragmatic Programmer   \n",
      "8                    Data Pipelines Pocket Reference   \n",
      "9  Official Google Cloud Certified Professional D...   \n",
      "\n",
      "                           Author                    Publisher Published Date  \\\n",
      "0                   Vlad Riscutia           Simon and Schuster     2021-08-17   \n",
      "1                   Paul Crickard         Packt Publishing Ltd     2020-10-23   \n",
      "2                      Adi Wijaya         Packt Publishing Ltd     2022-03-31   \n",
      "3  Manoj Kukreja, Danil Zburivsky         Packt Publishing Ltd     2021-10-22   \n",
      "4          Joe Reis, Matt Housley       \"O'Reilly Media, Inc.\"     2022-06-22   \n",
      "5                    Tobias Macey       \"O'Reilly Media, Inc.\"     2021-06-11   \n",
      "6                  Obie Fernandez            Pearson Education     2007-11-16   \n",
      "7       David Thomas, Andrew Hunt  Addison-Wesley Professional     2019-07-30   \n",
      "8                  James Densmore               O'Reilly Media     2021-02-10   \n",
      "9                    Dan Sullivan            John Wiley & Sons     2020-05-18   \n",
      "\n",
      "                                         Description  \n",
      "0  Build a data platform to the industry-leading ...  \n",
      "1  Build, monitor, and manage real-time data pipe...  \n",
      "2  Build and deploy your own data pipelines on GC...  \n",
      "3  Understand the complexities of modern-day data...  \n",
      "4  Data engineering has grown rapidly in the past...  \n",
      "5  Take advantage of today's sky-high demand for ...  \n",
      "6  The expert guide to building Ruby on Rails app...  \n",
      "7  “One of the most significant books in my life....  \n",
      "8  Data pipelines are the foundation for success ...  \n",
      "9  The proven Study Guide that prepares you for t...  \n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "\n",
    "def fetch_google_books_data(query, max_results=10):\n",
    "    url = f\"https://www.googleapis.com/books/v1/volumes?q={query}&maxResults={max_results}\"\n",
    "    response = requests.get(url)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        books = []\n",
    "        for item in data.get('items', []):\n",
    "            book_info = item['volumeInfo']\n",
    "            books.append({\n",
    "                \"Title\": book_info.get('title', 'N/A'),\n",
    "                \"Author\": ', '.join(book_info.get('authors', ['N/A'])),\n",
    "                \"Publisher\": book_info.get('publisher', 'N/A'),\n",
    "                \"Published Date\": book_info.get('publishedDate', 'N/A'),\n",
    "                \"Description\": book_info.get('description', 'N/A'),\n",
    "            })\n",
    "        return pd.DataFrame(books)\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. Status code: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "# Example Usage\n",
    "df = fetch_google_books_data(\"data engineering\", max_results=10)\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7f4ee982",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Author</th>\n",
       "      <th>Publisher</th>\n",
       "      <th>Published Date</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Data Engineering on Azure</td>\n",
       "      <td>Vlad Riscutia</td>\n",
       "      <td>Simon and Schuster</td>\n",
       "      <td>2021-08-17</td>\n",
       "      <td>Build a data platform to the industry-leading ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Data Engineering with Python</td>\n",
       "      <td>Paul Crickard</td>\n",
       "      <td>Packt Publishing Ltd</td>\n",
       "      <td>2020-10-23</td>\n",
       "      <td>Build, monitor, and manage real-time data pipe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Data Engineering with Google Cloud Platform</td>\n",
       "      <td>Adi Wijaya</td>\n",
       "      <td>Packt Publishing Ltd</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>Build and deploy your own data pipelines on GC...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Data Engineering with Apache Spark, Delta Lake...</td>\n",
       "      <td>Manoj Kukreja, Danil Zburivsky</td>\n",
       "      <td>Packt Publishing Ltd</td>\n",
       "      <td>2021-10-22</td>\n",
       "      <td>Understand the complexities of modern-day data...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Fundamentals of Data Engineering</td>\n",
       "      <td>Joe Reis, Matt Housley</td>\n",
       "      <td>\"O'Reilly Media, Inc.\"</td>\n",
       "      <td>2022-06-22</td>\n",
       "      <td>Data engineering has grown rapidly in the past...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Title  \\\n",
       "0                          Data Engineering on Azure   \n",
       "1                       Data Engineering with Python   \n",
       "2        Data Engineering with Google Cloud Platform   \n",
       "3  Data Engineering with Apache Spark, Delta Lake...   \n",
       "4                   Fundamentals of Data Engineering   \n",
       "\n",
       "                           Author               Publisher Published Date  \\\n",
       "0                   Vlad Riscutia      Simon and Schuster     2021-08-17   \n",
       "1                   Paul Crickard    Packt Publishing Ltd     2020-10-23   \n",
       "2                      Adi Wijaya    Packt Publishing Ltd     2022-03-31   \n",
       "3  Manoj Kukreja, Danil Zburivsky    Packt Publishing Ltd     2021-10-22   \n",
       "4          Joe Reis, Matt Housley  \"O'Reilly Media, Inc.\"     2022-06-22   \n",
       "\n",
       "                                         Description  \n",
       "0  Build a data platform to the industry-leading ...  \n",
       "1  Build, monitor, and manage real-time data pipe...  \n",
       "2  Build and deploy your own data pipelines on GC...  \n",
       "3  Understand the complexities of modern-day data...  \n",
       "4  Data engineering has grown rapidly in the past...  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f40dba",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "18a064f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0474338b",
   "metadata": {},
   "source": [
    "![pipeline_design.png](pipeline_design.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d06621c4",
   "metadata": {},
   "source": [
    "https://www.youtube.com/watch?v=3xyoM28B40Y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d61af-f3e8-4afc-a66b-3814e160aaf3",
   "metadata": {},
   "source": [
    "Now it's your turn!\n",
    "### Task 1: description of task\n",
    "\n",
    "    - instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed7ea-1940-434d-bb2d-601d07994783",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: white; padding: 10px; text-align: center;\">\n",
    "    <h1>_________________________________END________________________________\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86481-eae2-4019-9515-66a43a30f0fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; color: #fff; padding: 30px; text-align: center;\">\n",
    "    <h1>THANK YOU!\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2f04-f141-405d-8a9f-8cf186d66f41",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 30px;\">\n",
    "    <h4> Live Exercise Solutions\n",
    "        \n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9ddd9-5558-4b1d-a3e7-04c3dca33b6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d487-56ef-4c22-a1c9-d25e9df33e37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"  padding: 10px; text-align: center;\">\n",
    "    <font size=\"3\"> Programming Interveiw Questions</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e08c3f-3e5b-46a6-9fbb-456cbd850553",
   "metadata": {},
   "source": [
    "1. topic:\n",
    "    - question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b86c1-64b0-4abd-8ba9-54746bdc9007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5454f2e3-4fa4-48f9-936a-35be52d769af",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Mohammad Idrees Bhat --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92ba4c-672c-4e9f-b842-2b2d9234e5ff",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ffe4e1; color: #2f4f4f; padding: 10px; border-radius: 10px; width: 350px; text-align: center; float: right; margin: 20px 0;\">\n",
    "    Mohammad Idrees Bhat<br>\n",
    "    <span style=\"font-size: 12px; color: #696969;\">\n",
    "        Tech Skills Trainer | AI/ML Consultant\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc27b3-58d0-431e-8121-f1b4c08377c7",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
