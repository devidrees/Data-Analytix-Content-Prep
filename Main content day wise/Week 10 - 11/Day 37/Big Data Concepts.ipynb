{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bc666-34a1-47b6-8018-1ad79dafae95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #add8e6; padding: 10px; height: 70px; border-radius: 15px;\">\n",
    "    <div style=\"font-family: 'Georgia', serif; font-size: 20px; padding: 10px; text-align: right; position: absolute; right: 20px;\">\n",
    "        Mohammad Idrees Bhat <br>\n",
    "        <span style=\"font-family: 'Arial', sans-serif;font-size: 12px; color: #0a0a0a;\">Tech Skills Trainer | AI/ML Consultant</span> <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444d2e-97e9-49a8-bf3d-0119a2dfebb5",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ad3d8-0bce-4e29-86da-5ea91b5a69df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; padding: 10px; text-align: center; color: white; font-size: 32px; font-family: 'Arial', sans-serif;\">\n",
    "    title <br>\n",
    "    <h3 style=\"text-align: center; color: white; font-size: 15px; font-family: 'Arial', sans-serif;\">Sub heading</h3>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "155e8ec7-547b-41f4-b6f6-6e6e719c198c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: white; color: black; padding: 10px;\">\n",
    "    <h4><b>AGENDA</b> <p><p>\n",
    "1.  Introduction to Big Data<p><p> \n",
    "2.  Overview of Big Data ecosystem and tools <p>\n",
    "3.  Hands-on with Big Data Tools <p>\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c30b-e766-4658-8d70-1b0af10ae2f4",
   "metadata": {},
   "source": [
    "<!-- Link the Montserrat font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<!-- Main div with centered content and a flexible box size, no scroll bar -->\n",
    "<div style=\"background-color: #baf733; min-height: 100px; width: 100%; display: flex; justify-content: center; align-items: center; position: relative; padding: 20px; box-sizing: border-box; font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 20px; border-radius: 15px;\">\n",
    "    <div style=\"position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 14px; color: rgba(0, 0, 0, 0.05); border-radius: 10px;\">Mohammad Idrees Bhat</div>\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the below text with question -->\n",
    "    What do you think existed before the universe began? How did the universe begin?\n",
    "    <!-- Fill the above text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4912e6a6",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>1. Introduction to Big Data\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f0db613",
   "metadata": {},
   "source": [
    "**\"Where have you heard about Big Data, and how do you think it impacts our lives?\"**\n",
    "\n",
    "Here are some examples to inspire your thinking:  \n",
    "- Social media platforms store and analyze user interactions to personalize feeds.  \n",
    "- Online shopping websites use data to recommend products you might like.  \n",
    "- Traffic management systems use IoT devices to monitor and predict congestion in real time.  \n",
    "- Weather forecasting uses massive datasets from sensors and satellites to make accurate predictions.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caef9c0",
   "metadata": {},
   "source": [
    "**Big Data** refers to datasets that are so **large**, **fast**, or **complex** that traditional data processing methods cannot handle them effectively. \n",
    "\n",
    "These datasets require specialized tools and techniques to store, process, and analyze.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2267a09",
   "metadata": {},
   "source": [
    "**Why is Big Data important?**  \n",
    "In a world where data is constantly generated from devices, applications, and sensors, Big Data enables us to:  \n",
    "- Gain deeper insights into complex problems.  \n",
    "- Make informed decisions in real time.  \n",
    "- Build innovative solutions like recommendation systems, fraud detection, and more.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5acaec9",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4>The Five V’s of Big Data\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "448af8cb",
   "metadata": {},
   "source": [
    "To better understand Big Data, we use the **Five V’s** framework. Each \"V\" represents a key characteristic that defines Big Data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad6d6dc8",
   "metadata": {},
   "source": [
    "**1. Volume**\n",
    "- The amount of data generated is enormous, often measured in terabytes or even petabytes.  \n",
    "- **Example:** Social media platforms like Twitter and Instagram generate terabytes of data daily through posts, likes, and comments.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6db0799",
   "metadata": {},
   "source": [
    "**2. Velocity**\n",
    "- The speed at which data is generated and needs to be processed.  \n",
    "- **Example:** Stock market systems generate data in milliseconds, requiring real-time analysis to make predictions and decisions. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d93b912",
   "metadata": {},
   "source": [
    "**3. Variety**\n",
    "- Data comes in multiple formats, including:  \n",
    "  - **Structured:** Tabular data in databases.  \n",
    "  - **Unstructured:** Text, images, videos, etc.  \n",
    "  - **Semi-structured:** JSON, XML, etc.  \n",
    "- **Example:** A company might analyze customer emails (text), product images (pictures), and transaction records (structured data)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe366e5",
   "metadata": {},
   "source": [
    "**4. Veracity**\n",
    "- Refers to the uncertainty or accuracy of the data.  \n",
    "- Cleaning and validating noisy or incomplete data are critical for meaningful insights.  \n",
    "- **Example:** Customer reviews often have typos or inconsistencies that need to be addressed before analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced2e5a4",
   "metadata": {},
   "source": [
    "**5. Value**\n",
    "- The ultimate goal of Big Data is to derive **value**, insights that drive better decisions or create innovative solutions.  \n",
    "- **Example:** E-commerce websites use data to create personalized product recommendations, leading to improved user experiences and increased sales.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50c25245",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4>Real-World Applications of Big Data\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbe60a4",
   "metadata": {},
   "source": [
    "Big Data is transforming industries across the globe. Here are some examples:  \n",
    "\n",
    "**1. Healthcare**\n",
    "- Predict patient outcomes by analyzing data from electronic medical records (EMRs), wearable devices, and diagnostic tools.  \n",
    "- Example: Use Big Data to detect early signs of diseases like cancer through pattern recognition.  \n",
    "\n",
    "**2. E-commerce**\n",
    "- Personalized recommendations are powered by analyzing user behavior, search history, and purchase patterns.  \n",
    "- Example: Amazon suggests products based on your browsing and purchase history.  \n",
    "\n",
    "**3. Smart Cities**\n",
    "- Manage traffic, energy, and public services using IoT sensors and Big Data analytics.  \n",
    "- Example: Smart traffic lights adjust timings based on real-time traffic data to reduce congestion.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc887c11",
   "metadata": {},
   "source": [
    "Show a brief video clip on Big Data applications (3–5 minutes)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8e338",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9c249a1b",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3> 2. Overview of Big Data ecosystem and tools\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e7a5480",
   "metadata": {},
   "source": [
    "Now that we understand what Big Data is and its characteristics, let’s dive into the tools and technologies that make working with Big Data possible.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92159c23",
   "metadata": {},
   "source": [
    "**Overview of Big Data Tools and Technologies**\n",
    "\n",
    "The Big Data ecosystem consists of a variety of tools designed for storing, processing, and analyzing massive datasets. Let’s explore some of the most widely used tools:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd47575",
   "metadata": {},
   "source": [
    "- **Hadoop**: A framework for batch processing of large datasets.  \n",
    "  - Works by breaking down massive data into smaller chunks and processing them in parallel.  \n",
    "  - Ideal for scenarios where data can be processed in batches over time.  \n",
    "  - Example: Analyzing logs from a web server for monthly traffic trends.\n",
    "\n",
    "- **Spark**: A fast and distributed computing framework.  \n",
    "  - Processes data in-memory, making it significantly faster than Hadoop for many tasks.  \n",
    "  - Can handle both batch and stream processing.  \n",
    "  - Example: Real-time fraud detection in financial transactions.\n",
    "\n",
    "- **NoSQL Databases**: Designed for non-relational data storage and processing.  \n",
    "  - Examples include **MongoDB** and **Cassandra**.  \n",
    "  - Suitable for flexible data models like documents, key-value pairs, or wide-column stores.  \n",
    "  - Example: Storing user-generated content like reviews, images, or logs in an e-commerce system.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70207f7b",
   "metadata": {},
   "source": [
    "**Batch Processing vs. Stream Processing**\n",
    "\n",
    "Big Data processing can be broadly categorized into two types:  \n",
    "\n",
    "- **Batch Processing**:  \n",
    "  - Data is collected over a period, stored, and processed in chunks.  \n",
    "  - Tools like **Hadoop** are optimized for batch jobs.  \n",
    "  - **Example**: Generating daily sales reports for a company.  \n",
    "  - **Pros**: Suitable for large datasets that don’t require immediate analysis.  \n",
    "\n",
    "- **Stream Processing**:  \n",
    "  - Data is processed in real time as it is generated.  \n",
    "  - Tools like **Spark Streaming** are used for this purpose.  \n",
    "  - **Example**: Monitoring stock prices and triggering alerts for anomalies.  \n",
    "  - **Pros**: Enables real-time decision-making for time-sensitive applications.  \n",
    "\n",
    "---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af21442",
   "metadata": {},
   "source": [
    "1. **Apache Spark**  \n",
    "   - A fast and general-purpose cluster-computing system for large-scale data processing.\n",
    "\n",
    "2. **Hadoop (HDFS & MapReduce)**  \n",
    "   - A distributed storage and batch processing framework for big data.\n",
    "\n",
    "3. **Apache Kafka**  \n",
    "   - A distributed event streaming platform for high-throughput real-time data pipelines.\n",
    "\n",
    "4. **Tableau**  \n",
    "   - A powerful data visualization tool for creating interactive dashboards.\n",
    "\n",
    "5. **Amazon S3**  \n",
    "   - A cloud-based object storage service for scalable and durable data storage.\n",
    "\n",
    "6. **Google BigQuery**  \n",
    "   - A fully-managed, serverless data warehouse for fast SQL analytics on large datasets.\n",
    "\n",
    "7. **Power BI**  \n",
    "   - A business intelligence tool for data visualization and interactive reporting.\n",
    "\n",
    "8. **Elasticsearch (ELK Stack)**  \n",
    "   - A distributed search engine for real-time log analysis and monitoring.\n",
    "\n",
    "9. **Pandas (Python)**  \n",
    "   - A library for data manipulation and analysis with Python.\n",
    "\n",
    "10. **Presto**  \n",
    "    - A distributed SQL query engine for running analytics on large data sets.\n",
    "\n",
    "11. **Apache Cassandra**  \n",
    "    - A highly scalable NoSQL database for handling large volumes of structured data.\n",
    "\n",
    "12. **Apache Flink**  \n",
    "    - A stream processing framework for real-time analytics.\n",
    "\n",
    "13. **Apache Hive**  \n",
    "    - A data warehouse system for querying and analyzing large datasets using SQL.\n",
    "\n",
    "14. **Apache Airflow**  \n",
    "    - A workflow orchestration tool for scheduling and automating data pipelines.\n",
    "\n",
    "15. **Google Cloud Dataflow**  \n",
    "    - A unified stream and batch processing system for real-time data pipelines.\n",
    "\n",
    "16. **Apache Nifi**  \n",
    "    - A tool for automating and managing the flow of data between systems.\n",
    "\n",
    "17. **R**  \n",
    "    - A programming language and environment for statistical computing and graphics.\n",
    "\n",
    "18. **TensorFlow on Spark**  \n",
    "    - A framework for running deep learning workloads on Spark clusters.\n",
    "\n",
    "19. **Apache Mahout**  \n",
    "    - A scalable machine learning library for clustering, classification, and collaborative filtering.\n",
    "\n",
    "20. **H2O.ai**  \n",
    "    - An open-source machine learning platform for scalable model training.\n",
    "\n",
    "21. **Apache Oozie**  \n",
    "    - A workflow scheduler for managing Hadoop jobs.\n",
    "\n",
    "22. **Talend**  \n",
    "    - A tool for ETL (Extract, Transform, Load) and data integration workflows.\n",
    "\n",
    "23. **D3.js**  \n",
    "    - A JavaScript library for creating dynamic and interactive data visualizations.\n",
    "\n",
    "24. **Splunk**  \n",
    "    - A platform for analyzing machine-generated data to gain operational intelligence.\n",
    "\n",
    "25. **Apache Ranger**  \n",
    "    - A security tool for managing access control in big data ecosystems."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1a92a8",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4>Apache Hadoop\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e44226bf",
   "metadata": {},
   "source": [
    "[Hadoop](https://hadoop.apache.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31587777",
   "metadata": {},
   "source": [
    "**What is Hadoop?**\n",
    "\n",
    "\n",
    "Apache Hadoop is an open-source framework designed for distributed storage and processing of large datasets across clusters of computers. \n",
    "\n",
    "It allows organizations to store and analyze massive amounts of structured and unstructured data efficiently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fbcf62",
   "metadata": {},
   "source": [
    "**Key Components of Hadoop**\n",
    "\n",
    "[HDFS Architecture](https://hadoop.apache.org/docs/stable/hadoop-project-dist/hadoop-hdfs/HdfsDesign.html)\n",
    "\n",
    "1. **HDFS (Hadoop Distributed File System)**  \n",
    "   - A distributed file system that stores data across multiple machines, ensuring redundancy and fault tolerance.\n",
    "\n",
    "   - **Example:** A 1TB file can be split into smaller chunks (blocks) and stored across multiple machines. If one machine fails, the data remains accessible due to replication.\n",
    "\n",
    "   - **How it works:**\n",
    "\n",
    "   ![](https://media.geeksforgeeks.org/wp-content/uploads/20200621121959/3164-1.png)\n",
    "\n",
    "   -  In our local PC, by default the block size in Hard Disk is 4KB. When we install Hadoop, the HDFS by default changes the block size to 64 MB. \n",
    "\n",
    "   - Since it is used to store huge data. We can also change the block size to 128 MB. \n",
    "   \n",
    "   - Now HDFS works with Data Node and Name Node. \n",
    "   \n",
    "   - While Name Node is a master service and it keeps the metadata as for on which commodity hardware, the data is residing, the Data Node stores the actual data. \n",
    "   \n",
    "   - Now, since the block size is of 64 MB thus the storage required to store metadata is reduced thus making HDFS better. \n",
    "   \n",
    "   - Also, Hadoop stores three copies of every dataset at three different locations. This ensures that the Hadoop is not prone to single point of failure.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ead91a",
   "metadata": {},
   "source": [
    "2. **MapReduce**  \n",
    "   - A programming model for processing large datasets in a parallel and distributed manner. It consists of two main tasks:\n",
    "     - **Map:** Processes data and transforms it into key-value pairs.\n",
    "     - **Reduce:** Aggregates or processes the mapped data to produce meaningful results.\n",
    "   - **Example:** Counting the frequency of words in a large document using MapReduce.\n",
    "\n",
    "3. **YARN (Yet Another Resource Negotiator)**  \n",
    "   - Manages cluster resources and schedules jobs for execution. It ensures optimal resource utilization.\n",
    "   - **Example:** Allocating memory and CPU to different MapReduce jobs running on the cluster.\n",
    "\n",
    "4. **Hadoop Common**  \n",
    "   - A collection of libraries and utilities required by other Hadoop modules.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b82ca2e",
   "metadata": {},
   "source": [
    "**Features of Hadoop**\n",
    "\n",
    "- **Scalability:** Can handle petabytes of data by adding more nodes to the cluster.  \n",
    "- **Fault Tolerance:** Data is replicated across nodes, ensuring no data is lost even if a node fails.  \n",
    "- \n",
    "\n",
    "- **Cost-Effective:** Runs on commodity hardware, making it more affordable for organizations.  \n",
    "- **Support for Multiple Data Formats:** Handles structured, semi-structured, and unstructured data.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "208f9e46",
   "metadata": {},
   "source": [
    "**How Hadoop Works**\n",
    "\n",
    "1. **Data Storage:**  \n",
    "   Data is stored in HDFS, which splits large files into blocks (e.g., 128 MB) and distributes them across the cluster.  \n",
    "\n",
    "2. **Data Processing:**  \n",
    "   - The MapReduce framework processes data stored in HDFS by splitting tasks across nodes.  \n",
    "   - Each node processes its assigned block independently, reducing the time taken for computation.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18206d6f",
   "metadata": {},
   "source": [
    "**Hadoop Ecosystem**\n",
    "\n",
    "Hadoop integrates with a variety of tools for added functionality:\n",
    "- **Hive:** SQL-like querying for data in HDFS.  \n",
    "- **Pig:** A scripting platform for large-scale data analysis.  \n",
    "- **HBase:** A NoSQL database for real-time data processing.  \n",
    "- **Sqoop:** Imports and exports data between Hadoop and relational databases.  \n",
    "- **Flume:** Collects and ingests log data into HDFS."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ec3a34",
   "metadata": {},
   "source": [
    "![](https://static.packt-cdn.com/products/9781787281349/graphics/Ch09-Fig13.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d0afb0",
   "metadata": {},
   "source": [
    "**When to Use Hadoop**\n",
    "- When dealing with large datasets that exceed the storage and processing capabilities of a single machine.  \n",
    "- Batch processing scenarios, such as log analysis or data archiving.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f2614a9",
   "metadata": {},
   "source": [
    "**Limitations of Hadoop**\n",
    "1. **Batch Processing Only:** Hadoop MapReduce is not suitable for real-time data processing.  \n",
    "2. **Latency:** Processing can be slower compared to modern tools like Apache Spark.  \n",
    "3. **Complexity:** Requires advanced knowledge to implement and maintain.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff7f89f",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: black; padding: 4px;\">\n",
    "    <h4>Apache Spark\n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f726a8",
   "metadata": {},
   "source": [
    "[Spark](https://spark.apache.org/)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b5cb3f",
   "metadata": {},
   "source": [
    "**What is Apache Spark?**\n",
    "\n",
    "Apache Spark is an open-source, distributed computing system designed for fast and versatile big data processing. \n",
    "\n",
    "It extends the capabilities of Hadoop by providing real-time processing, in-memory computation, and a flexible programming interface.\n",
    "\n",
    "It is faster than Hadoop's MapReduce\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b950a1",
   "metadata": {},
   "source": [
    "**Key Components of Apache Spark**\n",
    "\n",
    "1. **Spark Core**  \n",
    "   - The foundational engine responsible for memory management, fault tolerance, and distributed task execution.  \n",
    "   - Provides APIs in Python (PySpark), Java, Scala, and R.  \n",
    "\n",
    "2. **Spark SQL**  \n",
    "   - Enables querying structured and semi-structured data using SQL-like syntax.  \n",
    "   - **Example:** Querying JSON or Parquet files directly using SQL commands.\n",
    "\n",
    "3. **Spark Streaming**  \n",
    "   - Processes real-time data streams from sources like Kafka, Flume, or socket streams.  \n",
    "   - **Example:** Real-time fraud detection in credit card transactions.\n",
    "\n",
    "4. **MLlib (Machine Learning Library)**  \n",
    "   - A scalable library for machine learning tasks such as classification, regression, clustering, and collaborative filtering.  \n",
    "   - **Example:** Building a recommendation system for e-commerce websites.\n",
    "\n",
    "5. **GraphX**  \n",
    "   - A library for graph processing and analysis, enabling tasks like PageRank and community detection.  \n",
    "   - **Example:** Social network analysis or influence detection in networks.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86a4b919",
   "metadata": {},
   "source": [
    "**Features of Apache Spark**\n",
    "\n",
    "- **In-Memory Processing:** Data is processed in memory, significantly speeding up computation.  \n",
    "- **Real-Time Data Processing:** Unlike Hadoop, Spark can process streaming data in near real-time.  \n",
    "- **Ease of Use:** Offers APIs for multiple languages (Python, Scala, Java, R).  \n",
    "- **Unified Framework:** Combines batch processing, streaming, and machine learning in one system.  \n",
    "- **Compatibility with Hadoop:** Works seamlessly with Hadoop’s HDFS and other ecosystem tools.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46eb3ced",
   "metadata": {},
   "source": [
    "**How Spark Works**\n",
    "\n",
    "1. **Driver Program:**  \n",
    "   - The entry point of a Spark application that coordinates all operations.  \n",
    "\n",
    "2. **Cluster Manager:**  \n",
    "   - Allocates resources for tasks (e.g., Spark Standalone, YARN, Mesos).  \n",
    "\n",
    "3. **Executors:**  \n",
    "   - Run tasks and manage data storage in memory or disk.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12432bca",
   "metadata": {},
   "source": [
    "**Spark Ecosystem**\n",
    "\n",
    "- **Data Sources:** Spark integrates with HDFS, Cassandra, MongoDB, and more.  \n",
    "- **Cluster Managers:** Supports Standalone, YARN, and Mesos.  \n",
    "- **Storage Formats:** Handles Parquet, ORC, Avro, JSON, CSV, and more.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "763c409c",
   "metadata": {},
   "source": [
    "**When to Use Spark**\n",
    "\n",
    "1. **Real-Time Data Processing:** Use Spark Streaming for scenarios like stock price monitoring or IoT applications.  \n",
    "2. **Batch and Stream Processing:** Unified framework eliminates the need for separate tools.  \n",
    "3. **Machine Learning Pipelines:** Build and deploy scalable ML models with MLlib.  \n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91de17d0",
   "metadata": {},
   "source": [
    "**Limitations of Spark**\n",
    "\n",
    "1. **Memory-Intensive:** Requires significant memory for in-memory computation.  \n",
    "2. **Cost:** More resource-heavy compared to Hadoop.  \n",
    "3. **Steeper Learning Curve:** Advanced optimizations may require deeper expertise.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aafabf76",
   "metadata": {},
   "source": [
    "**Spark vs. Hadoop**\n",
    "\n",
    "| Feature            | Apache Spark         | Apache Hadoop         |\n",
    "|---------------------|----------------------|-----------------------|\n",
    "| **Processing Mode** | Batch + Real-Time   | Batch Only            |\n",
    "| **Speed**           | Faster (In-Memory)  | Slower (Disk-Based)   |\n",
    "| **Ease of Use**     | APIs for multiple languages | Complex MapReduce setup |\n",
    "| **Fault Tolerance** | High                | High                  |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6139a8",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3>3. Hands-on with Big Data Tools\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eade1fff",
   "metadata": {},
   "source": [
    "\n",
    "Setting up Hadoop/Spark environment (use cloud-based sandbox tools)\n",
    "Loading and processing a sample dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2185430-3791-45df-824f-bdec6d7145e3",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\">\n",
    "    <b><font size=\"5\"> Live Exercise</font> </b>\n",
    "</div>\n",
    "\n",
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8d61af-f3e8-4afc-a66b-3814e160aaf3",
   "metadata": {},
   "source": [
    "Now it's your turn!\n",
    "### Task 1: description of task\n",
    "\n",
    "    - instructions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed7ea-1940-434d-bb2d-601d07994783",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: white; padding: 10px; text-align: center;\">\n",
    "    <h1>_________________________________END________________________________\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86481-eae2-4019-9515-66a43a30f0fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; color: #fff; padding: 30px; text-align: center;\">\n",
    "    <h1>THANK YOU!\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aefa2f04-f141-405d-8a9f-8cf186d66f41",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 30px;\">\n",
    "    <h4> Live Exercise Solutions\n",
    "        \n",
    "</h4> </div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1f9ddd9-5558-4b1d-a3e7-04c3dca33b6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'solutions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m solutions\n",
      "\u001b[1;31mNameError\u001b[0m: name 'solutions' is not defined"
     ]
    }
   ],
   "source": [
    "solutions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36f2d487-56ef-4c22-a1c9-d25e9df33e37",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-warning\"  padding: 10px; text-align: center;\">\n",
    "    <font size=\"3\"> Programming Interveiw Questions</font>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4e08c3f-3e5b-46a6-9fbb-456cbd850553",
   "metadata": {},
   "source": [
    "1. topic:\n",
    "    - question"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2b86c1-64b0-4abd-8ba9-54746bdc9007",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "5454f2e3-4fa4-48f9-936a-35be52d769af",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Mohammad Idrees Bhat --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92ba4c-672c-4e9f-b842-2b2d9234e5ff",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ffe4e1; color: #2f4f4f; padding: 10px; border-radius: 10px; width: 350px; text-align: center; float: right; margin: 20px 0;\">\n",
    "    Mohammad Idrees Bhat<br>\n",
    "    <span style=\"font-size: 12px; color: #696969;\">\n",
    "        Tech Skills Trainer | AI/ML Consultant\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc27b3-58d0-431e-8121-f1b4c08377c7",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
