{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c4bc666-34a1-47b6-8018-1ad79dafae95",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #add8e6; padding: 10px; height: 70px; border-radius: 15px;\">\n",
    "    <div style=\"font-family: 'Georgia', serif; font-size: 20px; padding: 10px; text-align: right; position: absolute; right: 50px;\">\n",
    "        Mohammad Idrees Bhat <br>\n",
    "        <span style=\"font-family: 'Arial', sans-serif;font-size: 12px; color: #0a0a0a;\">Tech Skills Trainer | AI/ML Consultant</span> <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "    </div>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef444d2e-97e9-49a8-bf3d-0119a2dfebb5",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151ad3d8-0bce-4e29-86da-5ea91b5a69df",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; padding: 10px; text-align: center; color: white; font-size: 32px; font-family: 'Arial', sans-serif; border-radius: 100px;\">\n",
    "    Hands-On Model Evaluation and Cross Validation<br>\n",
    "    <h3 style=\"text-align: center; color: white; font-size: 15px; font-family: 'Arial', sans-serif;\">  Techniques </h3>\n",
    "</div\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b1c30b-e766-4658-8d70-1b0af10ae2f4",
   "metadata": {},
   "source": [
    "<!-- Link the Montserrat font -->\n",
    "<link href=\"https://fonts.googleapis.com/css2?family=Montserrat:wght@700&display=swap\" rel=\"stylesheet\">\n",
    "\n",
    "<!-- Main div with centered content and a flexible box size, no scroll bar -->\n",
    "<div style=\"background-color: #baf733; min-height: 100%; width: 100%; display: flex; justify-content: center; align-items: center; position: relative; padding: 20px; box-sizing: border-box; font-family: 'Montserrat', sans-serif; font-weight: 700; font-size: 20px; border-radius: 15px;\">\n",
    "    <div style=\"position: absolute; top: 10px; right: 10px; padding: 5px 10px; font-size: 14px; color: rgba(0, 0, 0, 0.05); border-radius: 10px;\">Mohammad Idrees Bhat</div>\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the below text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "    <!-- Fill the above text with question -->\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53ec8637",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3> Practical Exercise: Model Evaluation\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944cad0b",
   "metadata": {},
   "source": [
    "- We will train a classification model to predict whether a passenger survived the Titanic disaster (binary classification: Survived = 1, Not Survived = 0)\n",
    "- We'll use the Titanic dataset from Kaggle, which contains information like passenger age, sex, class, etc.\n",
    "- We'll use Logistic Regression as our classifier.\n",
    "- We will calculate Accuracy, Precision, Recall and F1 Score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5ba16a0",
   "metadata": {},
   "source": [
    "### Dataset Overview:\n",
    "\n",
    "The Titanic dataset has the following features:\n",
    "\n",
    "- Survived: Whether the passenger survived (1 = Yes, 0 = No).\n",
    "- Pclass: Ticket class (1, 2, 3).\n",
    "- Name: Name of the passenger.\n",
    "- Sex: Gender of the passenger.\n",
    "- Age: Age of the passenger.\n",
    "- SibSp: Number of siblings/spouses aboard.\n",
    "- Parch: Number of parents/children aboard.\n",
    "- Fare: Fare paid for the ticket.\n",
    "- Embarked: Port of Embarkation (C = Cherbourg; Q = Queenstown; S = Southampton)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2afc190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21590e13",
   "metadata": {},
   "source": [
    "\"C:\\Users\\devid\\Desktop\\datasets\\titanic.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5bfc742",
   "metadata": {},
   "source": [
    "'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e32ddc90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load the Titanic dataset\n",
    "# We will load the dataset from a CSV file or from a dataset link (you can also download it from Kaggle)\n",
    "url = 'https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv'\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ae9c970f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 2: Data Preprocessing (filling missing values, encoding categorical features)\n",
    "# Dropping columns that are not useful for the model (for simplicity)\n",
    "df = df.drop(columns=['Name', 'Ticket', 'Cabin', 'Embarked'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7405fc88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devid\\AppData\\Local\\Temp\\ipykernel_32368\\1742747283.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Handle missing data (filling missing 'Age' values with the median of the column)\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "\n",
    "# Convert the 'Sex' column to numeric (0 for male, 1 for female)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "\n",
    "# For simplicity, we will use only a few features for training\n",
    "X = df[['Pclass', 'Sex', 'Age']]  # Features: Pclass (Class), Sex (Gender), Age (Age)\n",
    "y = df['Survived']  # Target: Survived (1 for survived, 0 for not survived)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2b824b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Split the dataset into training and test sets (80-20 split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2eb99db9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 4: Train the Logistic Regression model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3bcbbb01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 5: Make predictions on the test set\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ab3830a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Confusion Matrix:\n",
      "[[91 14]\n",
      " [20 54]]\n"
     ]
    }
   ],
   "source": [
    "# Step 8: Optional - Display confusion matrix to better understand model performance\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "print(\"\\nConfusion Matrix:\")\n",
    "print(conf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f1654a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 6: Model Evaluation - Calculate Accuracy, Precision, Recall, and F1-Score\n",
    "\n",
    "# Accuracy: Proportion of correct predictions\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Precision: Proportion of correctly predicted positives out of all predicted positives\n",
    "precision = precision_score(y_test, y_pred)\n",
    "\n",
    "# Recall: Proportion of correctly predicted positives out of all actual positives\n",
    "recall = recall_score(y_test, y_pred)\n",
    "\n",
    "# F1-Score: Harmonic mean of Precision and Recall\n",
    "f1 = f1_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957ebcaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Evaluation on Titanic dataset:\n",
      "Accuracy: 0.81\n",
      "Precision: 0.79\n",
      "Recall: 0.73\n",
      "F1-Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Step 7: Display the results\n",
    "print(\"Model Evaluation on Titanic dataset:\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\") \n",
    "print(f\"Precision: {precision:.2f}\")\n",
    "print(f\"Recall: {recall:.2f}\")\n",
    "print(f\"F1-Score: {f1:.2f}\")\n",
    "\n",
    "# The f-string allows us to format the accuracy value within the string.\n",
    "# {:.2f} ensures the accuracy is displayed as a floating-point number rounded to 2 decimal places.\n",
    "# For example, if the accuracy is 0.8467, it will print \"Accuracy: 0.85\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7626d480",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightgreen; color: black; padding: 4px;\">\n",
    "    <h3> Practical Exercise: Cross Validation\n",
    "</h3> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da401",
   "metadata": {},
   "source": [
    "- We'll use the Titanic dataset to perform cross-validation.\n",
    "- The metrics (Accuracy, Precision, Recall, F1-Score) will be evaluated using the K-Fold, Leave-One-Out (LOO), and Stratified K-Fold cross-validation methods.\n",
    "- The models will be evaluated with different folds, and the performance will be calculated based on the metrics learned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50f3660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold, StratifiedKFold, LeaveOneOut\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "780c07e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Titanic dataset\n",
    "url = \"https://raw.githubusercontent.com/datasciencedojo/datasets/master/titanic.csv\"\n",
    "df = pd.read_csv(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "25a64731",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\devid\\AppData\\Local\\Temp\\ipykernel_32368\\57131679.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Age'].fillna(df['Age'].median(), inplace=True)\n",
      "C:\\Users\\devid\\AppData\\Local\\Temp\\ipykernel_32368\\57131679.py:3: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
      "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
      "\n",
      "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
      "\n",
      "\n",
      "  df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n"
     ]
    }
   ],
   "source": [
    "# Preprocessing the dataset: Handling missing values and converting categorical data\n",
    "df['Age'].fillna(df['Age'].median(), inplace=True)\n",
    "df['Embarked'].fillna(df['Embarked'].mode()[0], inplace=True)\n",
    "df['Sex'] = df['Sex'].map({'male': 0, 'female': 1})\n",
    "df['Embarked'] = df['Embarked'].map({'C': 0, 'Q': 1, 'S': 2})\n",
    "\n",
    "# Selecting features and target variable\n",
    "X = df[['Pclass', 'Sex', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked']]\n",
    "y = df['Survived']\n",
    "\n",
    "# Standardizing the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bde30186",
   "metadata": {},
   "source": [
    "1. K-Fold Cross-Validation:\n",
    "\n",
    "In K-Fold cross-validation, the dataset is split into K equal-sized folds. Each fold will be used as a test set once, while the rest are used for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f62d4db3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K-Fold Cross-Validation:\n",
      "Accuracy: 0.80\n",
      "Precision: 0.75\n",
      "Recall: 0.70\n",
      "F1-Score: 0.73\n"
     ]
    }
   ],
   "source": [
    "# Initialize KFold Cross-Validation with 5 folds\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Storing metrics for each fold\n",
    "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "\n",
    "# Performing K-Fold Cross-Validation\n",
    "for train_index, test_index in kf.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Calculating metrics for each fold\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# Printing average metrics\n",
    "print(f\"K-Fold Cross-Validation:\")\n",
    "print(f\"Accuracy: {sum(accuracies) / len(accuracies):.2f}\")\n",
    "print(f\"Precision: {sum(precisions) / len(precisions):.2f}\")\n",
    "print(f\"Recall: {sum(recalls) / len(recalls):.2f}\")\n",
    "print(f\"F1-Score: {sum(f1_scores) / len(f1_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc749d9",
   "metadata": {},
   "source": [
    "2. Leave-One-Out Cross-Validation (LOO):\n",
    "\n",
    "Leave-One-Out Cross-Validation involves using one data point as a test set and the rest as a training set. This is repeated for each data point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "390d553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Leave-One-Out Cross-Validation:\n",
      "Accuracy: 0.79\n",
      "Precision: 0.27\n",
      "Recall: 0.27\n",
      "F1-Score: 0.27\n"
     ]
    }
   ],
   "source": [
    "# Initialize LeaveOneOut Cross-Validation\n",
    "loo = LeaveOneOut()\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Storing metrics for each fold\n",
    "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "\n",
    "# Performing Leave-One-Out Cross-Validation\n",
    "for train_index, test_index in loo.split(X_scaled):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Calculating metrics for each fold\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# Printing average metrics\n",
    "print(f\"Leave-One-Out Cross-Validation:\")\n",
    "print(f\"Accuracy: {sum(accuracies) / len(accuracies):.2f}\")\n",
    "print(f\"Precision: {sum(precisions) / len(precisions):.2f}\")\n",
    "print(f\"Recall: {sum(recalls) / len(recalls):.2f}\")\n",
    "print(f\"F1-Score: {sum(f1_scores) / len(f1_scores):.2f}\")\n",
    "\n",
    "\n",
    "import warnings\n",
    "# Suppress all warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "626e31f8",
   "metadata": {},
   "source": [
    "3. Stratified K-Fold Cross-Validation:\n",
    "\n",
    "Stratified K-Fold ensures that each fold has approximately the same percentage of samples of each target class. This is particularly useful when the target classes are imbalanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "addeec27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stratified K-Fold Cross-Validation:\n",
      "Accuracy: 0.79\n",
      "Precision: 0.74\n",
      "Recall: 0.70\n",
      "F1-Score: 0.72\n"
     ]
    }
   ],
   "source": [
    "# Initialize Stratified K-Fold Cross-Validation with 5 folds\n",
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "logreg = LogisticRegression(max_iter=200)\n",
    "\n",
    "# Storing metrics for each fold\n",
    "accuracies, precisions, recalls, f1_scores = [], [], [], []\n",
    "\n",
    "# Performing Stratified K-Fold Cross-Validation\n",
    "for train_index, test_index in skf.split(X_scaled, y):\n",
    "    X_train, X_test = X_scaled[train_index], X_scaled[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    logreg.fit(X_train, y_train)\n",
    "    y_pred = logreg.predict(X_test)\n",
    "\n",
    "    # Calculating metrics for each fold\n",
    "    accuracies.append(accuracy_score(y_test, y_pred))\n",
    "    precisions.append(precision_score(y_test, y_pred))\n",
    "    recalls.append(recall_score(y_test, y_pred))\n",
    "    f1_scores.append(f1_score(y_test, y_pred))\n",
    "\n",
    "# Printing average metrics\n",
    "print(f\"Stratified K-Fold Cross-Validation:\")\n",
    "print(f\"Accuracy: {sum(accuracies) / len(accuracies):.2f}\")\n",
    "print(f\"Precision: {sum(precisions) / len(precisions):.2f}\")\n",
    "print(f\"Recall: {sum(recalls) / len(recalls):.2f}\")\n",
    "print(f\"F1-Score: {sum(f1_scores) / len(f1_scores):.2f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ed7ea-1940-434d-bb2d-601d07994783",
   "metadata": {},
   "source": [
    "<div style=\"background-color: lightblue; color: white; padding: 10px; text-align: center;\">\n",
    "    <h1>____________________         BEST OF LUCK   ...  :)        _____________________\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13e86481-eae2-4019-9515-66a43a30f0fb",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #002147; color: #fff; padding: 30px; text-align: center;\">\n",
    "    <h1>THANK YOU!\n",
    "        <!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->\n",
    "</h1> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6ea230",
   "metadata": {},
   "source": [
    "### Uncovered Parts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f156410",
   "metadata": {},
   "source": [
    "**Standardization** is a technique used to scale features so that they have a mean of zero and a standard deviation of one. \n",
    "\n",
    "It is essential when using machine learning algorithms that are sensitive to the scale of the data, such as support vector machines (SVM), k-nearest neighbors (KNN), or gradient descent-based methods.\n",
    "\n",
    "**Why Standardization is Important:**\n",
    "\n",
    "- Fair Comparison of Features: If different features in your dataset have different units or magnitudes (e.g., age in years and income in thousands), some features may dominate others during model training. Standardization puts all features on the same scale.\n",
    "\n",
    "- Improves Model Performance: Algorithms like KNN and SVM depend on the distances between data points. If one feature has a larger scale than another, it can disproportionately affect the distance calculation and, in turn, the model's performance."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f052ef38",
   "metadata": {},
   "source": [
    "- https://www.youtube.com/watch?v=mnKm3YP56PY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "43aefffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-1.41421356 -1.41421356]\n",
      " [-0.70710678 -0.70710678]\n",
      " [ 0.          0.        ]\n",
      " [ 0.70710678  0.70710678]\n",
      " [ 1.41421356  1.41421356]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Example data (2 features, 5 samples)\n",
    "X = [[20, 300], [25, 400], [30, 500], [35, 600], [40, 700]]\n",
    "\n",
    "# Initialize the scaler\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit the scaler and transform the data\n",
    "X_standardized = scaler.fit_transform(X)\n",
    "\n",
    "print(X_standardized)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5454f2e3-4fa4-48f9-936a-35be52d769af",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Mohammad Idrees Bhat --->"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e92ba4c-672c-4e9f-b842-2b2d9234e5ff",
   "metadata": {},
   "source": [
    "<h2 style=\"background-color: #ffe4e1; color: #2f4f4f; padding: 10px; border-radius: 10px; width: 350px; text-align: center; float: right; margin: 20px 0;\">\n",
    "    Mohammad Idrees Bhat<br>\n",
    "    <span style=\"font-size: 12px; color: #696969;\">\n",
    "        Tech Skills Trainer | AI/ML Consultant\n",
    "    </span>\n",
    "</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15cc27b3-58d0-431e-8121-f1b4c08377c7",
   "metadata": {},
   "source": [
    "<!--- Mohammad Idrees Bhat | Tech Skills Trainer | AI/ML Consultant --->"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
